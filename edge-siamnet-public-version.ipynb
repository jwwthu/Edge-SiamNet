{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook is used to implement our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "img_rows, img_cols = 28 , 28\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we would show how to load the seven datasets used in our study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loading Kannada-MNIST and Dig-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first show how to load Kannada-MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = './data/kannada/Kannada_MNIST/X_kannada_MNIST_train.npz'\n",
    "f = np.load(input_fn)\n",
    "X_train = f['arr_0']\n",
    "input_fn = './data/kannada/Kannada_MNIST/y_kannada_MNIST_train.npz'\n",
    "f = np.load(input_fn)\n",
    "y_train = f['arr_0']\n",
    "input_fn = './data/kannada/Kannada_MNIST/X_kannada_MNIST_test.npz'\n",
    "f = np.load(input_fn)\n",
    "X_test = f['arr_0']\n",
    "input_fn = './data/kannada/Kannada_MNIST/y_kannada_MNIST_test.npz'\n",
    "f = np.load(input_fn)\n",
    "y_test = f['arr_0']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we show how to load Dig-MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = './data/kannada/Dig_MNIST/X_dig_MNIST.npz'\n",
    "f = np.load(input_fn)\n",
    "X_dig = f['arr_0']\n",
    "input_fn = './data/kannada/Dig_MNIST/y_dig_MNIST.npz'\n",
    "f = np.load(input_fn)\n",
    "y_dig = f['arr_0']\n",
    "print(X_dig.shape)\n",
    "print(y_dig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Loading Other Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other datasets, you only need to change the npz file name and use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_test_fn = './data/mnist.npz'\n",
    "data = np.load(input_train_test_fn)\n",
    "X_train, X_test, y_train, y_test = data['x_train'], data['x_test'], data['y_train'], data['y_test']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we show how to calculate edge images and how to implement the data augmentation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into training and validation sets\n",
    "X_train, X_vali, y_train, y_vali = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_vali.shape)\n",
    "print(y_train.shape)\n",
    "print(y_vali.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some functions for data augmentation\n",
    "def rotateImage(image, angle):\n",
    "    row, col = image.shape\n",
    "    center = tuple(np.array([row,col])/2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(center,angle, 1.0)\n",
    "    new_image = cv2.warpAffine(image, rot_mat, (col, row))\n",
    "    return new_image\n",
    "\n",
    "def translation(img):\n",
    "    rows, cols = img.shape\n",
    "\n",
    "    M = np.float32([[1, 0, random.randint(-5,5)], [0, 1, random.randint(-5,5)]])\n",
    "    dst = cv2.warpAffine(img,M, (cols, rows))\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the training data set with data augmentation techniques\n",
    "trainImage =[]\n",
    "edgeTrainImage = []\n",
    "trainLabel = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    img = X_train[i].astype(np.uint8)\n",
    "\n",
    "    trainImage.append(img)\n",
    "    \n",
    "    edgeImage = cv2.Canny(255 - img, 100, 200)\n",
    "    edgeTrainImage.append(edgeImage)\n",
    "\n",
    "    trainLabel.append(y_train[i])\n",
    "    \n",
    "    # Augment Input Image with Random Rotation\n",
    "    rotAngel = random.randint(-45, 45)\n",
    "    imgRot = rotateImage(img, rotAngel)\n",
    "    trainImage.append(imgRot)\n",
    "    \n",
    "    edgeImage = cv2.Canny(255 - imgRot, 100, 200)\n",
    "    edgeTrainImage.append(edgeImage)\n",
    "\n",
    "    trainLabel.append(y_train[i])\n",
    "    \n",
    "    # Augment Input Image with Block Effect\n",
    "    blocEffect = cv2.resize(img, (14, 44))\n",
    "    blocEffect = cv2.resize(blocEffect, (28, 28))\n",
    "    trainImage.append(blocEffect)\n",
    "\n",
    "    edgeImage = cv2.Canny(255 - blocEffect, 100, 200)\n",
    "    edgeTrainImage.append(edgeImage)\n",
    "    \n",
    "    trainLabel.append(y_train[i])\n",
    "    \n",
    "    # Augment Input Image with Translation\n",
    "    transImage = translation(img)\n",
    "    trainImage.append(transImage)\n",
    "\n",
    "    edgeImage = cv2.Canny(255 - transImage, 100, 200)\n",
    "    edgeTrainImage.append(edgeImage)\n",
    "    trainLabel.append(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "trainImage = np.array(trainImage, dtype=\"float\") / 255.0\n",
    "trainLabel = np.array(trainLabel)\n",
    "trainImage = trainImage.reshape(trainImage.shape[0], img_rows, img_cols, 1)\n",
    "edgeTrainImage = np.array(edgeTrainImage, dtype=\"float\") / 255.0\n",
    "edgeTrainImage = edgeTrainImage.reshape(edgeTrainImage.shape[0], img_rows, img_cols, 1)\n",
    "print (\"checking shape of the input array(s)\",trainImage.shape, edgeTrainImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the testing set\n",
    "testImage =[]\n",
    "edgeTestImage = []\n",
    "testLabel = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    img = X_test[i].astype(np.uint8)\n",
    "    testImage.append(img)\n",
    "    \n",
    "    edgeImage = cv2.Canny(255 - img, 100, 200)\n",
    "    edgeTestImage.append(edgeImage)\n",
    "    \n",
    "testLabel = y_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "testImage = np.array(testImage, dtype=\"float\") / 255.0\n",
    "testLabel = np.array(testLabel)\n",
    "testImage = testImage.reshape(testImage.shape[0], img_rows, img_cols, 1)\n",
    "edgeTestImage = np.array(edgeTestImage, dtype=\"float\") / 255.0\n",
    "edgeTestImage = edgeTestImage.reshape(edgeTestImage.shape[0], img_rows, img_cols, 1)\n",
    "print (\"checking shape of the input array(s)\",testImage.shape, edgeTestImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the validation set\n",
    "valiImage =[]\n",
    "edgeValiImage = []\n",
    "valiLabel = []\n",
    "    \n",
    "for i in range(X_vali.shape[0]):\n",
    "    img = X_vali[i].astype(np.uint8)\n",
    "    valiImage.append(img)\n",
    "        \n",
    "    edgeImage = cv2.Canny(255 - img, 100, 200)\n",
    "    edgeValiImage.append(edgeImage)\n",
    "        \n",
    "valiLabel = y_vali[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "valiImage = np.array(valiImage, dtype=\"float\") / 255.0\n",
    "valiLabel = np.array(valiLabel)\n",
    "valiImage = valiImage.reshape(valiImage.shape[0], img_rows, img_cols, 1)\n",
    "edgeValiImage = np.array(edgeValiImage, dtype=\"float\") / 255.0\n",
    "edgeValiImage = edgeValiImage.reshape(edgeValiImage.shape[0], img_rows, img_cols, 1)\n",
    "print (\"checking shape of the input array(s)\", valiImage.shape, edgeValiImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build y_train and y_test\n",
    "y_train = keras.utils.to_categorical(trainLabel, num_classes)\n",
    "y_test = keras.utils.to_categorical(testLabel, num_classes)\n",
    "y_vali = keras.utils.to_categorical(valiLabel, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# save weights based on the accuracy on the validation set, remeber to change the save path here\n",
    "checkpoint = ModelCheckpoint('./trained_model/with-data-augmentation/cnn/mnist/{val_acc:.4f}.hdf5',\n",
    "                             monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Keras Model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(trainImage, y_train,\n",
    "          batch_size=batch_size, shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=2,\n",
    "          validation_data=(valiImage, y_vali))\n",
    "score = model.evaluate(testImage, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 EdgeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "#Input PlaceHolder\n",
    "inpX = Input(input_shape)\n",
    "inpY = Input(input_shape)\n",
    "inputImg = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(inpX)\n",
    "inputEdge= Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputEdgeConv\")(inpY)\n",
    "    \n",
    "inputMerge = Add()([inputImg, inputEdge])\n",
    "layer1 = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer1\")(inputMerge)\n",
    "layer1 = Dropout(0.20, name=\"convLayer1Dropout\")(layer1)\n",
    "layer2 = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer2\")(layer1)\n",
    "layer3 = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer3\")(layer2)\n",
    "layer3 = Dropout(0.25, name=\"convLayer3Dropout\")(layer3)\n",
    "shortCut = Add(name=\"edgeShortcut\")([inpY, layer3])\n",
    "    \n",
    "layer4 = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer4\")(shortCut)\n",
    "layer4 = Dropout(0.25, name=\"convLayer4Dropout\")(layer4)\n",
    "layer4 = AveragePooling2D((2, 2), name=\"globalPoolLayer\")(layer4)\n",
    "denseLayer = Flatten()(layer4)\n",
    "denseLayer = Dense(128, activation='relu', name=\"denseLayer\")(denseLayer)\n",
    "denseLayer = Dropout(0.25, name=\"denseLayerDropout\")(denseLayer)\n",
    "outputLayer = Dense(num_classes, activation='softmax', name=\"classifier\")(denseLayer)\n",
    "model = Model([inpX, inpY], outputLayer)\n",
    "# save weights based on the accuracy on the validation set, remeber to change the save path here\n",
    "checkpoint = ModelCheckpoint('./trained_model/with-data-augmentation/edgenet/mnist/{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Keras Model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit([trainImage,edgeTrainImage], y_train,\n",
    "          batch_size=batch_size, shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=2,\n",
    "          validation_data=([valiImage, edgeValiImage], y_vali))\n",
    "score = model.evaluate([testImage, edgeTestImage], y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Edge-SiamNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    # x = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(input)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer1\")(input)\n",
    "    x = Dropout(0.20, name=\"convLayer1Dropout\")(x)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer2\")(x)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer3\")(x)\n",
    "    x = Dropout(0.25, name=\"convLayer3Dropout\")(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "inputImg = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(input_a)\n",
    "inputEdge= Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputEdgeConv\")(input_b)\n",
    "\n",
    "# inputMerge = Add()([inputImg, inputEdge])\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network((28, 28, 16))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(inputImg)\n",
    "processed_b = base_network(inputEdge)\n",
    "\n",
    "inputMerge = Add()([processed_a, processed_b])\n",
    "layer4 = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer4\")(inputMerge)\n",
    "layer4 = Dropout(0.25, name=\"convLayer4Dropout\")(layer4)\n",
    "layer4 = AveragePooling2D((2, 2), name=\"globalPoolLayer\")(layer4)\n",
    "denseLayer = Flatten()(layer4)\n",
    "denseLayer = Dense(128, activation='relu', name=\"denseLayer\")(denseLayer)\n",
    "denseLayer = Dropout(0.25, name=\"denseLayerDropout\")(denseLayer)\n",
    "outputLayer = Dense(num_classes, activation='softmax', name=\"classifier\")(denseLayer)\n",
    "model = Model([input_a, input_b], outputLayer)\n",
    "# save weights based on the accuracy on the validation set, remeber to change the save path here\n",
    "checkpoint = ModelCheckpoint('./trained_model/with-data-augmentation/edge-siamnet/mnist/{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Keras Model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit([trainImage, edgeTrainImage], y_train,\n",
    "          batch_size=batch_size, shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=2,\n",
    "          validation_data=([valiImage,edgeValiImage], y_vali))\n",
    "score = model.evaluate([testImage, edgeTestImage], y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Edge-TripleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    # x = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(input)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer1\")(input)\n",
    "    x = Dropout(0.20, name=\"convLayer1Dropout\")(x)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer2\")(x)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer3\")(x)\n",
    "    x = Dropout(0.25, name=\"convLayer3Dropout\")(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "inputImg = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(input_a)\n",
    "inputEdge= Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputEdgeConv\")(input_b)\n",
    "\n",
    "inputMerge = Add()([inputImg, inputEdge])\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network((28, 28, 16))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(inputImg)\n",
    "processed_b = base_network(inputEdge)\n",
    "processed_c = base_network(inputMerge)\n",
    "\n",
    "inputMerge = Add()([processed_a, processed_b, processed_c])\n",
    "layer4 = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer4\")(inputMerge)\n",
    "layer4 = Dropout(0.25, name=\"convLayer4Dropout\")(layer4)\n",
    "layer4 = AveragePooling2D((2, 2), name=\"globalPoolLayer\")(layer4)\n",
    "denseLayer = Flatten()(layer4)\n",
    "denseLayer = Dense(128, activation='relu', name=\"denseLayer\")(denseLayer)\n",
    "denseLayer = Dropout(0.25, name=\"denseLayerDropout\")(denseLayer)\n",
    "outputLayer = Dense(num_classes, activation='softmax', name=\"classifier\")(denseLayer)\n",
    "model = Model([input_a, input_b], outputLayer)\n",
    "# save weights based on the accuracy on the validation set, remeber to change the save path here\n",
    "checkpoint = ModelCheckpoint('./trained_model/with-data-augmentation/edge-triplenet/mnist/{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "#Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Keras Model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit([trainImage, edgeTrainImage], y_train,\n",
    "          batch_size=batch_size, shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=2,\n",
    "          validation_data=([valiImage,edgeValiImage], y_vali))\n",
    "score = model.evaluate([testImage, edgeTestImage], y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Use trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we show how to use the trained models. We build models as the same as the previous section, but then we load the weights directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to change the number here\n",
    "best_weight = '0.9951'\n",
    "\n",
    "# Compile Keras Model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "# load weights\n",
    "model.load_weights('./trained_model/with-data-augmentation/cnn/mnist/%s.hdf5' % best_weight)\n",
    "\n",
    "score = model.evaluate(testImage, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 EdgeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "#Input PlaceHolder\n",
    "inpX = Input(input_shape)\n",
    "inpY = Input(input_shape)\n",
    "inputImg = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(inpX)\n",
    "inputEdge= Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputEdgeConv\")(inpY)\n",
    "    \n",
    "inputMerge = Add()([inputImg, inputEdge])\n",
    "layer1 = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer1\")(inputMerge)\n",
    "layer1 = Dropout(0.20, name=\"convLayer1Dropout\")(layer1)\n",
    "layer2 = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer2\")(layer1)\n",
    "layer3 = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer3\")(layer2)\n",
    "layer3 = Dropout(0.25, name=\"convLayer3Dropout\")(layer3)\n",
    "shortCut = Add(name=\"edgeShortcut\")([inpY, layer3])\n",
    "    \n",
    "layer4 = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer4\")(shortCut)\n",
    "layer4 = Dropout(0.25, name=\"convLayer4Dropout\")(layer4)\n",
    "layer4 = AveragePooling2D((2, 2), name=\"globalPoolLayer\")(layer4)\n",
    "denseLayer = Flatten()(layer4)\n",
    "denseLayer = Dense(128, activation='relu', name=\"denseLayer\")(denseLayer)\n",
    "denseLayer = Dropout(0.25, name=\"denseLayerDropout\")(denseLayer)\n",
    "outputLayer = Dense(num_classes, activation='softmax', name=\"classifier\")(denseLayer)\n",
    "model = Model([inpX, inpY], outputLayer)\n",
    "\n",
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to change the number here\n",
    "best_weight = '0.9956'\n",
    "\n",
    "# Compile Keras Model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "# load weights\n",
    "model.load_weights('./trained_model/with-data-augmentation/edgenet/mnist/%s.hdf5' % best_weight)\n",
    "\n",
    "score = model.evaluate([testImage, edgeTestImage], y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Edge-SiamNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    # x = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(input)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer1\")(input)\n",
    "    x = Dropout(0.20, name=\"convLayer1Dropout\")(x)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer2\")(x)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer3\")(x)\n",
    "    x = Dropout(0.25, name=\"convLayer3Dropout\")(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "inputImg = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(input_a)\n",
    "inputEdge= Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputEdgeConv\")(input_b)\n",
    "\n",
    "# inputMerge = Add()([inputImg, inputEdge])\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network((28, 28, 16))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(inputImg)\n",
    "processed_b = base_network(inputEdge)\n",
    "\n",
    "inputMerge = Add()([processed_a, processed_b])\n",
    "layer4 = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer4\")(inputMerge)\n",
    "layer4 = Dropout(0.25, name=\"convLayer4Dropout\")(layer4)\n",
    "layer4 = AveragePooling2D((2, 2), name=\"globalPoolLayer\")(layer4)\n",
    "denseLayer = Flatten()(layer4)\n",
    "denseLayer = Dense(128, activation='relu', name=\"denseLayer\")(denseLayer)\n",
    "denseLayer = Dropout(0.25, name=\"denseLayerDropout\")(denseLayer)\n",
    "outputLayer = Dense(num_classes, activation='softmax', name=\"classifier\")(denseLayer)\n",
    "model = Model([input_a, input_b], outputLayer)\n",
    "\n",
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to change the number here\n",
    "best_weight = '0.9957'\n",
    "\n",
    "# Compile Keras Model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "# load weights\n",
    "model.load_weights('./trained_model/with-data-augmentation/edge-siamnet/mnist/%s.hdf5' % best_weight)\n",
    "\n",
    "score = model.evaluate([testImage, edgeTestImage], y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Edge-TripleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    # x = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(input)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer1\")(input)\n",
    "    x = Dropout(0.20, name=\"convLayer1Dropout\")(x)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer2\")(x)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2), activation='relu', name=\"convLayer3\")(x)\n",
    "    x = Dropout(0.25, name=\"convLayer3Dropout\")(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "input_a = Input(input_shape)\n",
    "input_b = Input(input_shape)\n",
    "\n",
    "inputImg = Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputImgConv\")(input_a)\n",
    "inputEdge= Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', name=\"inputEdgeConv\")(input_b)\n",
    "\n",
    "inputMerge = Add()([inputImg, inputEdge])\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network((28, 28, 16))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(inputImg)\n",
    "processed_b = base_network(inputEdge)\n",
    "processed_c = base_network(inputMerge)\n",
    "\n",
    "inputMerge = Add()([processed_a, processed_b, processed_c])\n",
    "layer4 = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', name=\"convLayer4\")(inputMerge)\n",
    "layer4 = Dropout(0.25, name=\"convLayer4Dropout\")(layer4)\n",
    "layer4 = AveragePooling2D((2, 2), name=\"globalPoolLayer\")(layer4)\n",
    "denseLayer = Flatten()(layer4)\n",
    "denseLayer = Dense(128, activation='relu', name=\"denseLayer\")(denseLayer)\n",
    "denseLayer = Dropout(0.25, name=\"denseLayerDropout\")(denseLayer)\n",
    "outputLayer = Dense(num_classes, activation='softmax', name=\"classifier\")(denseLayer)\n",
    "model = Model([input_a, input_b], outputLayer)\n",
    "\n",
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to change the number here\n",
    "best_weight = '0.9957'\n",
    "\n",
    "# Compile Keras Model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "# load weights\n",
    "model.load_weights('./trained_model/with-data-augmentation/edge-triplenet/mnist/%s.hdf5' % best_weight)\n",
    "\n",
    "score = model.evaluate([testImage, edgeTestImage], y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
